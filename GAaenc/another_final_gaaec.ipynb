{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from utils_new import mnist, plot_graphs, plot_mnist\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x, n, device=None):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.Tensor(x).to(torch.long)\n",
    "    one_hot = torch.zeros((x.shape[0], n))\n",
    "    one_hot.scatter_(1, x[:, None], 1.)\n",
    "    if device is not None:\n",
    "        one_hot = one_hot.to(device)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'FC_GAE_results'\n",
    "fixed_folder = root_folder + '/Fixed_results/'\n",
    "recon_folder = root_folder + '/Recon_results/'\n",
    "\n",
    "if os.path.isdir(root_folder):\n",
    "    !rm -r $root_folder\n",
    "os.mkdir(root_folder)\n",
    "os.mkdir(fixed_folder)\n",
    "os.mkdir(recon_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tanh = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "                lambda x: x.to(device)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "lr = 0.0001\n",
    "prior_size = 10\n",
    "train_epoch = 1000\n",
    "batch_size = 250\n",
    "train_loader, valid_loader, test_loader = mnist(batch_size=batch_size, valid=10000, transform=mnist_tanh)\n",
    "fixed_z = torch.randn((10, prior_size)).repeat((1,10)).view(-1, prior_size).to(device)\n",
    "fixed_z_label = to_onehot(torch.tensor(list(range(10))).repeat((10)), 10).to(device)\n",
    "fixed_data, fixed_label = next(iter(test_loader))\n",
    "fixed_data = fixed_data[:100].to(device)\n",
    "fixed_label = to_onehot(fixed_label[:100], 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh(), flatten=False, \n",
    "                 last_fn=None, first_fn=None, device='cpu'):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = []\n",
    "        self.flatten = flatten\n",
    "        if first_fn is not None:\n",
    "            layers.append(first_fn)\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            layers.append(activation_fn) # нам не нужен дропаут и фнкция активации в последнем слое\n",
    "        else: \n",
    "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "        if last_fn is not None:\n",
    "            layers.append(last_fn)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        if y is not None:\n",
    "            x = torch.cat([x, y], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enc = FullyConnected([28*28, 1024, 1024, prior_size], activation_fn=nn.LeakyReLU(0.2), flatten=True, device=device)\n",
    "\n",
    "Dec = FullyConnected([prior_size, 1024, 1024, 28*28], activation_fn=nn.LeakyReLU(0.2), last_fn=nn.Tanh(), device=device)\n",
    "Disc = FullyConnected([prior_size, 1024, 1024, 1], dropout=0.3, activation_fn=nn.LeakyReLU(0.2), device=device)\n",
    "\n",
    "Enc_optimizer = optim.Adam(Enc.parameters(), lr=lr)\n",
    "Dec_optimizer = optim.Adam(Dec.parameters(), lr=lr)\n",
    "Disc_optimizer = optim.Adam(Disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = {'E': [],'AE': [], 'D': []}\n",
    "test_log = {'E': [],'AE': [], 'D': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_zeros = torch.zeros((batch_size, 1)).to(device)\n",
    "batch_ones = torch.ones((batch_size, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, Enc, Dec, Disc, log=None):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        label = to_onehot(label, 10, device)\n",
    "        # train D\n",
    "        Enc.zero_grad()\n",
    "        Disc.zero_grad()\n",
    "        \n",
    "        z = torch.randn((batch_size, prior_size)).to(device)\n",
    "\n",
    "        fake_pred = Disc(Enc(data))\n",
    "        true_pred = Disc(z)\n",
    "\n",
    "        \n",
    "        fake_loss = F.binary_cross_entropy_with_logits(fake_pred, batch_zeros)\n",
    "        true_loss = F.binary_cross_entropy_with_logits(true_pred, batch_ones)\n",
    "        \n",
    "        Disc_loss = 0.5*(fake_loss + true_loss)\n",
    "        \n",
    "        Disc_loss.backward()\n",
    "        Disc_optimizer.step()\n",
    "        # train AE\n",
    "        Enc.zero_grad()\n",
    "        Dec.zero_grad()\n",
    "        Disc.zero_grad()\n",
    "        \n",
    "        z = torch.randn((batch_size, prior_size))\n",
    "        \n",
    "        latent = Enc(data)\n",
    "        \n",
    "        reconstructed = Dec(latent).view(-1, 1, 28, 28)\n",
    "        fake_pred = Disc(latent)\n",
    "        \n",
    "        Enc_loss = F.binary_cross_entropy_with_logits(fake_pred, batch_ones)\n",
    "        AE_loss = F.mse_loss(reconstructed, data)\n",
    "        G_loss = AE_loss + Enc_loss\n",
    "        \n",
    "        G_loss.backward()\n",
    "        Dec_optimizer.step()\n",
    "        Enc_optimizer.step()\n",
    "            \n",
    "        if batch_idx % 100 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = 'E: {:.4f}, AE: {:.4f}, D: {:.4f}'.format(Enc_loss.item(), AE_loss.item(), Disc_loss.item())\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = 'E: {:.4f}, AE: {:.4f}, D: {:.4f}'.format(Enc_loss.item(), AE_loss.item(), Disc_loss.item())\n",
    "        print(line + losses)\n",
    "        log['E'].append(Enc_loss.item())\n",
    "        log['AE'].append(AE_loss.item())\n",
    "        log['D'].append(Disc_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(Enc, Dec, Disc, loader, epoch, log=None):\n",
    "    test_size = len(loader)\n",
    "    E_loss = 0.\n",
    "    AE_loss = 0.\n",
    "    D_loss = 0.\n",
    "    test_loss = {'E': 0., 'AE': 0., 'D': 0.}\n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            label = to_onehot(label, 10, device)\n",
    "            z = torch.randn((batch_size, prior_size)).to(device)\n",
    "            latent = Enc(data)\n",
    "            reconstructed = Dec(latent).view(-1, 1, 28, 28)\n",
    "            fake_pred = Disc(latent)\n",
    "            true_pred = Disc(z)\n",
    "        \n",
    "            fake_loss = F.binary_cross_entropy_with_logits(fake_pred, batch_zeros).item()\n",
    "            true_loss = F.binary_cross_entropy_with_logits(true_pred, batch_ones).item()\n",
    "            \n",
    "            D_loss += 0.5*(fake_loss + true_loss)\n",
    "            E_loss += F.binary_cross_entropy_with_logits(fake_pred, batch_ones).item()\n",
    "            AE_loss += F.mse_loss(reconstructed, data)\n",
    "            \n",
    "        E_loss /= test_size\n",
    "        D_loss /= test_size\n",
    "        AE_loss /= test_size\n",
    "\n",
    "        fixed_gen = Dec(fixed_z).cpu().data.numpy().reshape(100, 1, 28, 28)\n",
    "        plot_mnist(fixed_gen, (10, 10), False, fixed_folder + '%03d.png' % epoch)\n",
    "        fixed_reconstruction = Dec(Enc(fixed_data)).cpu().data.numpy().reshape(100, 1, 28, 28)\n",
    "        plot_mnist(fixed_reconstruction, (10, 10), False, recon_folder + '%03d.png' % epoch)\n",
    "        \n",
    "    report = 'Test losses. E: {:.4f}, AE: {:.4f}, D: {:.4f}'.format(E_loss, AE_loss, D_loss)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLosses E: 0.6809, AE: 0.9240, D: 0.6987\n",
      "Train Epoch: 1 [25000/50000 (50%)]\tLosses E: 1.4953, AE: 0.2748, D: 5.7161\n",
      "Train Epoch: 1 [50000/50000 (100%)]\tLosses E: 0.8699, AE: 0.2786, D: 1.6772\n",
      "Test losses. E: 0.8521, AE: 0.2751, D: 1.6651\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLosses E: 0.8569, AE: 0.2762, D: 1.6244\n",
      "Train Epoch: 2 [25000/50000 (50%)]\tLosses E: 0.6200, AE: 0.2628, D: 1.0018\n",
      "Train Epoch: 2 [50000/50000 (100%)]\tLosses E: 0.9810, AE: 0.2660, D: 0.8875\n",
      "Test losses. E: 0.6697, AE: 0.2675, D: 0.9060\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLosses E: 1.0087, AE: 0.2601, D: 0.8616\n",
      "Train Epoch: 3 [25000/50000 (50%)]\tLosses E: 0.5828, AE: 0.2662, D: 0.9127\n",
      "Train Epoch: 3 [50000/50000 (100%)]\tLosses E: 0.4959, AE: 0.2499, D: 0.8243\n",
      "Test losses. E: 0.4575, AE: 0.2564, D: 0.8212\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLosses E: 0.4882, AE: 0.2549, D: 0.8317\n",
      "Train Epoch: 4 [25000/50000 (50%)]\tLosses E: 0.7889, AE: 0.2428, D: 0.8168\n",
      "Train Epoch: 4 [50000/50000 (100%)]\tLosses E: 0.5526, AE: 0.2472, D: 0.7929\n",
      "Test losses. E: 0.5427, AE: 0.2475, D: 0.7885\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLosses E: 0.5551, AE: 0.2462, D: 0.7995\n",
      "Train Epoch: 5 [25000/50000 (50%)]\tLosses E: 0.5285, AE: 0.2372, D: 0.8159\n",
      "Train Epoch: 5 [50000/50000 (100%)]\tLosses E: 0.6436, AE: 0.2446, D: 0.8027\n",
      "Test losses. E: 0.6095, AE: 0.2427, D: 0.7983\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLosses E: 0.6423, AE: 0.2352, D: 0.8107\n",
      "Train Epoch: 6 [25000/50000 (50%)]\tLosses E: 0.6104, AE: 0.2429, D: 0.7551\n",
      "Train Epoch: 6 [50000/50000 (100%)]\tLosses E: 0.6768, AE: 0.2399, D: 0.6738\n",
      "Test losses. E: 0.6595, AE: 0.2474, D: 0.6731\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLosses E: 0.6694, AE: 0.2477, D: 0.6749\n",
      "Train Epoch: 7 [25000/50000 (50%)]\tLosses E: 0.6787, AE: 0.2365, D: 0.8119\n",
      "Train Epoch: 7 [50000/50000 (100%)]\tLosses E: 0.5795, AE: 0.2237, D: 0.7303\n",
      "Test losses. E: 0.5748, AE: 0.2299, D: 0.7250\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLosses E: 0.5798, AE: 0.2292, D: 0.7277\n",
      "Train Epoch: 8 [25000/50000 (50%)]\tLosses E: 0.4311, AE: 0.2331, D: 0.7955\n",
      "Train Epoch: 8 [50000/50000 (100%)]\tLosses E: 0.7123, AE: 0.2282, D: 0.7721\n",
      "Test losses. E: 0.6857, AE: 0.2259, D: 0.7719\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLosses E: 0.7276, AE: 0.2272, D: 0.7630\n",
      "Train Epoch: 9 [25000/50000 (50%)]\tLosses E: 0.6762, AE: 0.2236, D: 0.6776\n",
      "Train Epoch: 9 [50000/50000 (100%)]\tLosses E: 0.6584, AE: 0.2187, D: 0.7157\n",
      "Test losses. E: 0.5814, AE: 0.2230, D: 0.7267\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLosses E: 0.6575, AE: 0.2198, D: 0.7288\n",
      "Train Epoch: 10 [25000/50000 (50%)]\tLosses E: 0.6588, AE: 0.2047, D: 0.7421\n",
      "Train Epoch: 10 [50000/50000 (100%)]\tLosses E: 0.4984, AE: 0.2110, D: 0.7931\n",
      "Test losses. E: 0.4892, AE: 0.2087, D: 0.7930\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLosses E: 0.4983, AE: 0.2051, D: 0.7982\n",
      "Train Epoch: 11 [25000/50000 (50%)]\tLosses E: 0.6375, AE: 0.1916, D: 0.7334\n",
      "Train Epoch: 11 [50000/50000 (100%)]\tLosses E: 0.5845, AE: 0.1906, D: 0.7266\n",
      "Test losses. E: 0.5805, AE: 0.1866, D: 0.7268\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLosses E: 0.5828, AE: 0.1875, D: 0.7305\n",
      "Train Epoch: 12 [25000/50000 (50%)]\tLosses E: 0.6432, AE: 0.2065, D: 0.7738\n",
      "Train Epoch: 12 [50000/50000 (100%)]\tLosses E: 0.6611, AE: 0.1907, D: 0.7623\n",
      "Test losses. E: 0.6610, AE: 0.1887, D: 0.7519\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLosses E: 0.6606, AE: 0.1870, D: 0.7577\n",
      "Train Epoch: 13 [25000/50000 (50%)]\tLosses E: 0.5897, AE: 0.1699, D: 0.7004\n",
      "Train Epoch: 13 [50000/50000 (100%)]\tLosses E: 0.7092, AE: 0.1741, D: 0.7597\n",
      "Test losses. E: 0.6841, AE: 0.1738, D: 0.7526\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLosses E: 0.7209, AE: 0.1770, D: 0.7523\n",
      "Train Epoch: 14 [25000/50000 (50%)]\tLosses E: 0.6383, AE: 0.1694, D: 0.7007\n",
      "Train Epoch: 14 [50000/50000 (100%)]\tLosses E: 0.6279, AE: 0.1632, D: 0.7323\n",
      "Test losses. E: 0.6213, AE: 0.1637, D: 0.7295\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLosses E: 0.6217, AE: 0.1584, D: 0.7338\n",
      "Train Epoch: 15 [25000/50000 (50%)]\tLosses E: 0.6485, AE: 0.1536, D: 0.7479\n",
      "Train Epoch: 15 [50000/50000 (100%)]\tLosses E: 0.6567, AE: 0.1504, D: 0.6961\n",
      "Test losses. E: 0.6450, AE: 0.1509, D: 0.6925\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLosses E: 0.6621, AE: 0.1492, D: 0.6897\n",
      "Train Epoch: 16 [25000/50000 (50%)]\tLosses E: 0.5920, AE: 0.1905, D: 0.8041\n",
      "Train Epoch: 16 [50000/50000 (100%)]\tLosses E: 0.7126, AE: 0.1568, D: 0.7270\n",
      "Test losses. E: 0.7121, AE: 0.1523, D: 0.7256\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLosses E: 0.7114, AE: 0.1594, D: 0.7261\n",
      "Train Epoch: 17 [25000/50000 (50%)]\tLosses E: 0.6425, AE: 0.1462, D: 0.6737\n",
      "Train Epoch: 17 [50000/50000 (100%)]\tLosses E: 2.6163, AE: 0.3382, D: 0.5630\n",
      "Test losses. E: 2.2350, AE: 0.3299, D: 0.5578\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLosses E: 2.7789, AE: 0.3236, D: 0.5500\n",
      "Train Epoch: 18 [25000/50000 (50%)]\tLosses E: 0.6838, AE: 0.1490, D: 0.7335\n",
      "Train Epoch: 18 [50000/50000 (100%)]\tLosses E: 0.5984, AE: 0.1545, D: 0.6801\n",
      "Test losses. E: 0.5932, AE: 0.1533, D: 0.6856\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLosses E: 0.5930, AE: 0.1516, D: 0.6906\n",
      "Train Epoch: 19 [25000/50000 (50%)]\tLosses E: 0.8403, AE: 0.1799, D: 0.7809\n",
      "Train Epoch: 19 [50000/50000 (100%)]\tLosses E: 0.6786, AE: 0.1406, D: 0.7024\n",
      "Test losses. E: 0.6788, AE: 0.1413, D: 0.7015\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLosses E: 0.6768, AE: 0.1382, D: 0.7013\n",
      "Train Epoch: 20 [25000/50000 (50%)]\tLosses E: 0.5534, AE: 0.1588, D: 0.7219\n",
      "Train Epoch: 20 [50000/50000 (100%)]\tLosses E: 0.7397, AE: 0.1599, D: 0.7671\n",
      "Test losses. E: 0.7395, AE: 0.1582, D: 0.7611\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLosses E: 0.7365, AE: 0.1580, D: 0.7609\n",
      "Train Epoch: 21 [25000/50000 (50%)]\tLosses E: 0.6418, AE: 0.1418, D: 0.6731\n",
      "Train Epoch: 21 [50000/50000 (100%)]\tLosses E: 0.5935, AE: 0.2470, D: 0.7886\n",
      "Test losses. E: 0.5273, AE: 0.2389, D: 0.8080\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLosses E: 0.5511, AE: 0.2315, D: 0.8153\n",
      "Train Epoch: 22 [25000/50000 (50%)]\tLosses E: 0.7354, AE: 0.1422, D: 0.7224\n",
      "Train Epoch: 22 [50000/50000 (100%)]\tLosses E: 0.6439, AE: 0.1456, D: 0.6893\n",
      "Test losses. E: 0.6379, AE: 0.1507, D: 0.6846\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLosses E: 0.6469, AE: 0.1460, D: 0.6882\n",
      "Train Epoch: 23 [25000/50000 (50%)]\tLosses E: 0.7344, AE: 0.1656, D: 0.7508\n",
      "Train Epoch: 23 [50000/50000 (100%)]\tLosses E: 0.7064, AE: 0.1417, D: 0.7004\n",
      "Test losses. E: 0.7017, AE: 0.1441, D: 0.7002\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLosses E: 0.7040, AE: 0.1410, D: 0.7049\n",
      "Train Epoch: 24 [25000/50000 (50%)]\tLosses E: 0.9080, AE: 0.1568, D: 0.6375\n",
      "Train Epoch: 24 [50000/50000 (100%)]\tLosses E: 0.7047, AE: 0.1406, D: 0.7302\n",
      "Test losses. E: 0.7010, AE: 0.1389, D: 0.7242\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLosses E: 0.7012, AE: 0.1369, D: 0.7228\n",
      "Train Epoch: 25 [25000/50000 (50%)]\tLosses E: 0.6486, AE: 0.1611, D: 0.7181\n",
      "Train Epoch: 25 [50000/50000 (100%)]\tLosses E: 0.6682, AE: 0.1372, D: 0.7184\n",
      "Test losses. E: 0.6665, AE: 0.1341, D: 0.7178\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLosses E: 0.6684, AE: 0.1383, D: 0.7139\n",
      "Train Epoch: 26 [25000/50000 (50%)]\tLosses E: 0.7806, AE: 0.1480, D: 0.6889\n",
      "Train Epoch: 26 [50000/50000 (100%)]\tLosses E: 0.7002, AE: 0.1317, D: 0.6874\n",
      "Test losses. E: 0.6978, AE: 0.1335, D: 0.6864\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLosses E: 0.7002, AE: 0.1358, D: 0.6881\n",
      "Train Epoch: 27 [25000/50000 (50%)]\tLosses E: 0.6754, AE: 0.1408, D: 0.7104\n",
      "Train Epoch: 27 [50000/50000 (100%)]\tLosses E: 0.6840, AE: 0.1255, D: 0.6957\n",
      "Test losses. E: 0.6802, AE: 0.1270, D: 0.6958\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLosses E: 0.6835, AE: 0.1267, D: 0.6963\n",
      "Train Epoch: 28 [25000/50000 (50%)]\tLosses E: 0.6842, AE: 0.1320, D: 0.7161\n",
      "Train Epoch: 28 [50000/50000 (100%)]\tLosses E: 0.7433, AE: 0.1362, D: 0.7189\n",
      "Test losses. E: 0.7417, AE: 0.1343, D: 0.7179\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLosses E: 0.7451, AE: 0.1343, D: 0.7184\n",
      "Train Epoch: 29 [25000/50000 (50%)]\tLosses E: 0.8100, AE: 0.1368, D: 0.6771\n",
      "Train Epoch: 29 [50000/50000 (100%)]\tLosses E: 0.6666, AE: 0.1407, D: 0.7102\n",
      "Test losses. E: 0.6588, AE: 0.1332, D: 0.7091\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLosses E: 0.6648, AE: 0.1355, D: 0.7045\n",
      "Train Epoch: 30 [25000/50000 (50%)]\tLosses E: 0.6393, AE: 0.1308, D: 0.7201\n",
      "Train Epoch: 30 [50000/50000 (100%)]\tLosses E: 0.6642, AE: 0.1188, D: 0.7019\n",
      "Test losses. E: 0.6625, AE: 0.1204, D: 0.6996\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLosses E: 0.6639, AE: 0.1149, D: 0.6992\n",
      "Train Epoch: 31 [25000/50000 (50%)]\tLosses E: 0.6535, AE: 0.1185, D: 0.7112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [50000/50000 (100%)]\tLosses E: 0.6824, AE: 0.1181, D: 0.6978\n",
      "Test losses. E: 0.6817, AE: 0.1169, D: 0.6974\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLosses E: 0.6862, AE: 0.1181, D: 0.6945\n",
      "Train Epoch: 32 [25000/50000 (50%)]\tLosses E: 0.6481, AE: 0.1184, D: 0.7043\n",
      "Train Epoch: 32 [50000/50000 (100%)]\tLosses E: 0.6445, AE: 0.1182, D: 0.7252\n",
      "Test losses. E: 0.6385, AE: 0.1223, D: 0.7255\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLosses E: 0.6413, AE: 0.1229, D: 0.7265\n",
      "Train Epoch: 33 [25000/50000 (50%)]\tLosses E: 0.7477, AE: 0.1277, D: 0.7159\n",
      "Train Epoch: 33 [50000/50000 (100%)]\tLosses E: 0.6299, AE: 0.1109, D: 0.7038\n",
      "Test losses. E: 0.6245, AE: 0.1122, D: 0.7058\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLosses E: 0.6271, AE: 0.1141, D: 0.7057\n",
      "Train Epoch: 34 [25000/50000 (50%)]\tLosses E: 0.8236, AE: 0.1453, D: 0.7101\n",
      "Train Epoch: 34 [50000/50000 (100%)]\tLosses E: 0.7229, AE: 0.1198, D: 0.6884\n",
      "Test losses. E: 0.7167, AE: 0.1157, D: 0.6883\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLosses E: 0.7200, AE: 0.1110, D: 0.6923\n",
      "Train Epoch: 35 [25000/50000 (50%)]\tLosses E: 0.6700, AE: 0.1177, D: 0.7228\n",
      "Train Epoch: 35 [50000/50000 (100%)]\tLosses E: 0.6526, AE: 0.1150, D: 0.7017\n",
      "Test losses. E: 0.6504, AE: 0.1155, D: 0.7010\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLosses E: 0.6596, AE: 0.1275, D: 0.6969\n",
      "Train Epoch: 36 [25000/50000 (50%)]\tLosses E: 0.6626, AE: 0.1164, D: 0.7091\n",
      "Train Epoch: 36 [50000/50000 (100%)]\tLosses E: 0.7514, AE: 0.1147, D: 0.6960\n",
      "Test losses. E: 0.7504, AE: 0.1139, D: 0.6976\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLosses E: 0.7536, AE: 0.1145, D: 0.6988\n",
      "Train Epoch: 37 [25000/50000 (50%)]\tLosses E: 0.7646, AE: 0.1202, D: 0.6879\n",
      "Train Epoch: 37 [50000/50000 (100%)]\tLosses E: 0.6880, AE: 0.1112, D: 0.7085\n",
      "Test losses. E: 0.6873, AE: 0.1121, D: 0.7048\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLosses E: 0.6849, AE: 0.1120, D: 0.7095\n",
      "Train Epoch: 38 [25000/50000 (50%)]\tLosses E: 0.6618, AE: 0.1051, D: 0.6941\n",
      "Train Epoch: 38 [50000/50000 (100%)]\tLosses E: 0.6467, AE: 0.1089, D: 0.6963\n",
      "Test losses. E: 0.6414, AE: 0.1078, D: 0.6970\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLosses E: 0.6445, AE: 0.1073, D: 0.6952\n",
      "Train Epoch: 39 [25000/50000 (50%)]\tLosses E: 0.6720, AE: 0.0970, D: 0.6885\n",
      "Train Epoch: 39 [50000/50000 (100%)]\tLosses E: 0.6999, AE: 0.1254, D: 0.7456\n",
      "Test losses. E: 0.7022, AE: 0.1274, D: 0.7399\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLosses E: 0.6971, AE: 0.1274, D: 0.7445\n",
      "Train Epoch: 40 [25000/50000 (50%)]\tLosses E: 0.6657, AE: 0.1207, D: 0.7271\n",
      "Train Epoch: 40 [50000/50000 (100%)]\tLosses E: 0.7071, AE: 0.1226, D: 0.7244\n",
      "Test losses. E: 0.7073, AE: 0.1279, D: 0.7208\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLosses E: 0.7089, AE: 0.1306, D: 0.7213\n",
      "Train Epoch: 41 [25000/50000 (50%)]\tLosses E: 0.7131, AE: 0.1091, D: 0.6848\n",
      "Train Epoch: 41 [50000/50000 (100%)]\tLosses E: 0.6742, AE: 0.1155, D: 0.7042\n",
      "Test losses. E: 0.6695, AE: 0.1126, D: 0.7066\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLosses E: 0.6692, AE: 0.1094, D: 0.7084\n",
      "Train Epoch: 42 [25000/50000 (50%)]\tLosses E: 0.6672, AE: 0.1013, D: 0.7049\n",
      "Train Epoch: 42 [50000/50000 (100%)]\tLosses E: 0.6398, AE: 0.0995, D: 0.7042\n",
      "Test losses. E: 0.6400, AE: 0.1013, D: 0.7046\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLosses E: 0.6407, AE: 0.1011, D: 0.7049\n",
      "Train Epoch: 43 [25000/50000 (50%)]\tLosses E: 0.7850, AE: 0.1365, D: 0.7138\n",
      "Train Epoch: 43 [50000/50000 (100%)]\tLosses E: 0.7450, AE: 0.1082, D: 0.6915\n",
      "Test losses. E: 0.7390, AE: 0.1108, D: 0.6919\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLosses E: 0.7397, AE: 0.1119, D: 0.6893\n",
      "Train Epoch: 44 [25000/50000 (50%)]\tLosses E: 0.6855, AE: 0.1102, D: 0.7095\n",
      "Train Epoch: 44 [50000/50000 (100%)]\tLosses E: 0.7639, AE: 0.1152, D: 0.6859\n",
      "Test losses. E: 0.7518, AE: 0.1174, D: 0.6878\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLosses E: 0.7664, AE: 0.1153, D: 0.6884\n",
      "Train Epoch: 45 [25000/50000 (50%)]\tLosses E: 0.6808, AE: 0.0901, D: 0.6989\n",
      "Train Epoch: 45 [50000/50000 (100%)]\tLosses E: 0.6766, AE: 0.0933, D: 0.6959\n",
      "Test losses. E: 0.6748, AE: 0.0954, D: 0.6957\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLosses E: 0.6756, AE: 0.0966, D: 0.6919\n",
      "Train Epoch: 46 [25000/50000 (50%)]\tLosses E: 0.6457, AE: 0.1132, D: 0.7214\n",
      "Train Epoch: 46 [50000/50000 (100%)]\tLosses E: 0.6085, AE: 0.1036, D: 0.7061\n",
      "Test losses. E: 0.6066, AE: 0.1030, D: 0.7091\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLosses E: 0.6104, AE: 0.1018, D: 0.7110\n",
      "Train Epoch: 47 [25000/50000 (50%)]\tLosses E: 0.6597, AE: 0.0969, D: 0.6901\n",
      "Train Epoch: 47 [50000/50000 (100%)]\tLosses E: 0.7160, AE: 0.0965, D: 0.6933\n",
      "Test losses. E: 0.7110, AE: 0.0946, D: 0.6948\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLosses E: 0.7108, AE: 0.0979, D: 0.6947\n",
      "Train Epoch: 48 [25000/50000 (50%)]\tLosses E: 0.7027, AE: 0.1176, D: 0.7146\n",
      "Train Epoch: 48 [50000/50000 (100%)]\tLosses E: 1.0270, AE: 0.2031, D: 0.6395\n",
      "Test losses. E: 0.9517, AE: 0.2169, D: 0.6242\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLosses E: 1.0668, AE: 0.2215, D: 0.6254\n",
      "Train Epoch: 49 [25000/50000 (50%)]\tLosses E: 0.6489, AE: 0.1156, D: 0.6936\n",
      "Train Epoch: 49 [50000/50000 (100%)]\tLosses E: 0.6727, AE: 0.0992, D: 0.6890\n",
      "Test losses. E: 0.6708, AE: 0.1033, D: 0.6896\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLosses E: 0.6725, AE: 0.1056, D: 0.6877\n",
      "Train Epoch: 50 [25000/50000 (50%)]\tLosses E: 0.7344, AE: 0.1145, D: 0.7036\n",
      "Train Epoch: 50 [50000/50000 (100%)]\tLosses E: 0.7664, AE: 0.1074, D: 0.6947\n",
      "Test losses. E: 0.7590, AE: 0.1096, D: 0.6958\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLosses E: 0.7618, AE: 0.1124, D: 0.6967\n",
      "Train Epoch: 51 [25000/50000 (50%)]\tLosses E: 0.7980, AE: 0.1398, D: 0.6913\n",
      "Train Epoch: 51 [50000/50000 (100%)]\tLosses E: 0.6686, AE: 0.1079, D: 0.7067\n",
      "Test losses. E: 0.6636, AE: 0.1108, D: 0.7102\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLosses E: 0.6654, AE: 0.1186, D: 0.7086\n",
      "Train Epoch: 52 [25000/50000 (50%)]\tLosses E: 0.6985, AE: 0.1016, D: 0.6990\n",
      "Train Epoch: 52 [50000/50000 (100%)]\tLosses E: 0.6987, AE: 0.1063, D: 0.6895\n",
      "Test losses. E: 0.6952, AE: 0.1058, D: 0.6893\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLosses E: 0.6967, AE: 0.1084, D: 0.6894\n",
      "Train Epoch: 53 [25000/50000 (50%)]\tLosses E: 0.6598, AE: 0.0982, D: 0.6940\n",
      "Train Epoch: 53 [50000/50000 (100%)]\tLosses E: 0.7112, AE: 0.0940, D: 0.7030\n",
      "Test losses. E: 0.7114, AE: 0.0977, D: 0.6990\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLosses E: 0.7178, AE: 0.0984, D: 0.6993\n",
      "Train Epoch: 54 [25000/50000 (50%)]\tLosses E: 0.6986, AE: 0.0973, D: 0.6934\n",
      "Train Epoch: 54 [50000/50000 (100%)]\tLosses E: 0.6474, AE: 0.1050, D: 0.7035\n",
      "Test losses. E: 0.6493, AE: 0.1001, D: 0.7009\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLosses E: 0.6490, AE: 0.0996, D: 0.7000\n",
      "Train Epoch: 55 [25000/50000 (50%)]\tLosses E: 0.6960, AE: 0.0912, D: 0.6924\n",
      "Train Epoch: 55 [50000/50000 (100%)]\tLosses E: 0.6828, AE: 0.0922, D: 0.6943\n",
      "Test losses. E: 0.6803, AE: 0.0927, D: 0.6947\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLosses E: 0.6823, AE: 0.0912, D: 0.6898\n",
      "Train Epoch: 56 [25000/50000 (50%)]\tLosses E: 0.6828, AE: 0.0920, D: 0.6944\n",
      "Train Epoch: 56 [50000/50000 (100%)]\tLosses E: 0.6579, AE: 0.0935, D: 0.6887\n",
      "Test losses. E: 0.6551, AE: 0.0951, D: 0.6909\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLosses E: 0.6559, AE: 0.0912, D: 0.6916\n",
      "Train Epoch: 57 [25000/50000 (50%)]\tLosses E: 0.6410, AE: 0.0925, D: 0.7031\n",
      "Train Epoch: 57 [50000/50000 (100%)]\tLosses E: 0.7092, AE: 0.1032, D: 0.7260\n",
      "Test losses. E: 0.6975, AE: 0.1050, D: 0.7300\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLosses E: 0.6936, AE: 0.1003, D: 0.7373\n",
      "Train Epoch: 58 [25000/50000 (50%)]\tLosses E: 0.7412, AE: 0.0948, D: 0.6915\n",
      "Train Epoch: 58 [50000/50000 (100%)]\tLosses E: 0.6912, AE: 0.0841, D: 0.6906\n",
      "Test losses. E: 0.6887, AE: 0.0863, D: 0.6898\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLosses E: 0.6890, AE: 0.0787, D: 0.6899\n",
      "Train Epoch: 59 [25000/50000 (50%)]\tLosses E: 0.7515, AE: 0.1309, D: 0.6894\n",
      "Train Epoch: 59 [50000/50000 (100%)]\tLosses E: 0.6906, AE: 0.0892, D: 0.7033\n",
      "Test losses. E: 0.6920, AE: 0.0935, D: 0.6993\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLosses E: 0.6982, AE: 0.0902, D: 0.6991\n",
      "Train Epoch: 60 [25000/50000 (50%)]\tLosses E: 0.6602, AE: 0.0838, D: 0.7022\n",
      "Train Epoch: 60 [50000/50000 (100%)]\tLosses E: 0.7027, AE: 0.0927, D: 0.7126\n",
      "Test losses. E: 0.6980, AE: 0.0907, D: 0.7125\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLosses E: 0.7021, AE: 0.0908, D: 0.7134\n",
      "Train Epoch: 61 [25000/50000 (50%)]\tLosses E: 0.7529, AE: 0.0846, D: 0.6902\n",
      "Train Epoch: 61 [50000/50000 (100%)]\tLosses E: 0.6391, AE: 0.0823, D: 0.6826\n",
      "Test losses. E: 0.6366, AE: 0.0845, D: 0.6823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62 [0/50000 (0%)]\tLosses E: 0.6373, AE: 0.0835, D: 0.6814\n",
      "Train Epoch: 62 [25000/50000 (50%)]\tLosses E: 0.6170, AE: 0.1137, D: 0.7293\n",
      "Train Epoch: 62 [50000/50000 (100%)]\tLosses E: 0.6715, AE: 0.0948, D: 0.6989\n",
      "Test losses. E: 0.6716, AE: 0.0954, D: 0.6976\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLosses E: 0.6725, AE: 0.0959, D: 0.6981\n",
      "Train Epoch: 63 [25000/50000 (50%)]\tLosses E: 0.6507, AE: 0.0976, D: 0.7043\n",
      "Train Epoch: 63 [50000/50000 (100%)]\tLosses E: 0.7024, AE: 0.0890, D: 0.6844\n",
      "Test losses. E: 0.6981, AE: 0.0939, D: 0.6856\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLosses E: 0.7022, AE: 0.0916, D: 0.6844\n",
      "Train Epoch: 64 [25000/50000 (50%)]\tLosses E: 0.7429, AE: 0.0966, D: 0.7052\n",
      "Train Epoch: 64 [50000/50000 (100%)]\tLosses E: 0.7153, AE: 0.0895, D: 0.6978\n",
      "Test losses. E: 0.7105, AE: 0.0900, D: 0.6982\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLosses E: 0.7121, AE: 0.0873, D: 0.6987\n",
      "Train Epoch: 65 [25000/50000 (50%)]\tLosses E: 0.7047, AE: 0.0817, D: 0.6921\n",
      "Train Epoch: 65 [50000/50000 (100%)]\tLosses E: 0.6282, AE: 0.0951, D: 0.7122\n",
      "Test losses. E: 0.6216, AE: 0.0930, D: 0.7142\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLosses E: 0.6281, AE: 0.0950, D: 0.7141\n",
      "Train Epoch: 66 [25000/50000 (50%)]\tLosses E: 0.7386, AE: 0.0916, D: 0.6847\n",
      "Train Epoch: 66 [50000/50000 (100%)]\tLosses E: 0.6381, AE: 0.0876, D: 0.7049\n",
      "Test losses. E: 0.6371, AE: 0.0888, D: 0.7036\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLosses E: 0.6383, AE: 0.0842, D: 0.7034\n",
      "Train Epoch: 67 [25000/50000 (50%)]\tLosses E: 0.6668, AE: 0.0871, D: 0.7041\n",
      "Train Epoch: 67 [50000/50000 (100%)]\tLosses E: 0.6236, AE: 0.0913, D: 0.6911\n",
      "Test losses. E: 0.6248, AE: 0.0879, D: 0.6904\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLosses E: 0.6257, AE: 0.0815, D: 0.6892\n",
      "Train Epoch: 68 [25000/50000 (50%)]\tLosses E: 0.6326, AE: 0.0882, D: 0.7074\n",
      "Train Epoch: 68 [50000/50000 (100%)]\tLosses E: 0.7023, AE: 0.0935, D: 0.7071\n",
      "Test losses. E: 0.7021, AE: 0.0929, D: 0.7073\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLosses E: 0.6980, AE: 0.0861, D: 0.7070\n",
      "Train Epoch: 69 [25000/50000 (50%)]\tLosses E: 0.7131, AE: 0.0882, D: 0.7035\n",
      "Train Epoch: 69 [50000/50000 (100%)]\tLosses E: 0.7878, AE: 0.0921, D: 0.6866\n",
      "Test losses. E: 0.7806, AE: 0.0924, D: 0.6845\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLosses E: 0.7943, AE: 0.0956, D: 0.6855\n",
      "Train Epoch: 70 [25000/50000 (50%)]\tLosses E: 0.6033, AE: 0.0895, D: 0.7152\n",
      "Train Epoch: 70 [50000/50000 (100%)]\tLosses E: 0.7079, AE: 0.0810, D: 0.6960\n",
      "Test losses. E: 0.7062, AE: 0.0818, D: 0.6952\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLosses E: 0.7014, AE: 0.0777, D: 0.6955\n",
      "Train Epoch: 71 [25000/50000 (50%)]\tLosses E: 0.6611, AE: 0.0855, D: 0.6973\n",
      "Train Epoch: 71 [50000/50000 (100%)]\tLosses E: 0.6928, AE: 0.0936, D: 0.6963\n",
      "Test losses. E: 0.6888, AE: 0.0932, D: 0.6938\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLosses E: 0.6961, AE: 0.0886, D: 0.6955\n",
      "Train Epoch: 72 [25000/50000 (50%)]\tLosses E: 0.7122, AE: 0.0800, D: 0.6946\n",
      "Train Epoch: 72 [50000/50000 (100%)]\tLosses E: 0.6929, AE: 0.0935, D: 0.7095\n",
      "Test losses. E: 0.6868, AE: 0.0917, D: 0.7104\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLosses E: 0.6991, AE: 0.0935, D: 0.7103\n",
      "Train Epoch: 73 [25000/50000 (50%)]\tLosses E: 0.8150, AE: 0.1109, D: 0.6995\n",
      "Train Epoch: 73 [50000/50000 (100%)]\tLosses E: 0.6869, AE: 0.0950, D: 0.6915\n",
      "Test losses. E: 0.6829, AE: 0.0993, D: 0.6905\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLosses E: 0.6856, AE: 0.1033, D: 0.6899\n",
      "Train Epoch: 74 [25000/50000 (50%)]\tLosses E: 0.6719, AE: 0.0919, D: 0.7074\n",
      "Train Epoch: 74 [50000/50000 (100%)]\tLosses E: 0.7306, AE: 0.0896, D: 0.7019\n",
      "Test losses. E: 0.7303, AE: 0.0873, D: 0.7010\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLosses E: 0.7313, AE: 0.0869, D: 0.7003\n",
      "Train Epoch: 75 [25000/50000 (50%)]\tLosses E: 0.6803, AE: 0.0809, D: 0.6964\n",
      "Train Epoch: 75 [50000/50000 (100%)]\tLosses E: 0.7171, AE: 0.0851, D: 0.6958\n",
      "Test losses. E: 0.7135, AE: 0.0880, D: 0.6966\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLosses E: 0.7137, AE: 0.0863, D: 0.6942\n",
      "Train Epoch: 76 [25000/50000 (50%)]\tLosses E: 0.7212, AE: 0.0974, D: 0.7102\n",
      "Train Epoch: 76 [50000/50000 (100%)]\tLosses E: 0.6721, AE: 0.0813, D: 0.6974\n",
      "Test losses. E: 0.6714, AE: 0.0820, D: 0.6980\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLosses E: 0.6710, AE: 0.0810, D: 0.6997\n",
      "Train Epoch: 77 [25000/50000 (50%)]\tLosses E: 0.6732, AE: 0.0811, D: 0.6973\n",
      "Train Epoch: 77 [50000/50000 (100%)]\tLosses E: 0.7059, AE: 0.0816, D: 0.6973\n",
      "Test losses. E: 0.7035, AE: 0.0845, D: 0.7013\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLosses E: 0.7052, AE: 0.0853, D: 0.7007\n",
      "Train Epoch: 78 [25000/50000 (50%)]\tLosses E: 0.7190, AE: 0.0876, D: 0.6952\n",
      "Train Epoch: 78 [50000/50000 (100%)]\tLosses E: 0.6829, AE: 0.0756, D: 0.6989\n",
      "Test losses. E: 0.6795, AE: 0.0813, D: 0.6999\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLosses E: 0.6816, AE: 0.0820, D: 0.6995\n",
      "Train Epoch: 79 [25000/50000 (50%)]\tLosses E: 0.6922, AE: 0.0827, D: 0.6954\n",
      "Train Epoch: 79 [50000/50000 (100%)]\tLosses E: 0.6715, AE: 0.0750, D: 0.6963\n",
      "Test losses. E: 0.6699, AE: 0.0789, D: 0.6957\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLosses E: 0.6706, AE: 0.0782, D: 0.6965\n",
      "Train Epoch: 80 [25000/50000 (50%)]\tLosses E: 0.6933, AE: 0.0810, D: 0.7045\n",
      "Train Epoch: 80 [50000/50000 (100%)]\tLosses E: 0.7596, AE: 0.0919, D: 0.7119\n",
      "Test losses. E: 0.7550, AE: 0.0955, D: 0.7117\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLosses E: 0.7528, AE: 0.0950, D: 0.7136\n",
      "Train Epoch: 81 [25000/50000 (50%)]\tLosses E: 0.6994, AE: 0.0884, D: 0.6964\n",
      "Train Epoch: 81 [50000/50000 (100%)]\tLosses E: 0.6777, AE: 0.0827, D: 0.6883\n",
      "Test losses. E: 0.6753, AE: 0.0825, D: 0.6908\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLosses E: 0.6757, AE: 0.0804, D: 0.6905\n",
      "Train Epoch: 82 [25000/50000 (50%)]\tLosses E: 0.7025, AE: 0.0950, D: 0.7016\n",
      "Train Epoch: 82 [50000/50000 (100%)]\tLosses E: 0.7631, AE: 0.0927, D: 0.7031\n",
      "Test losses. E: 0.7614, AE: 0.0911, D: 0.7036\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    Enc.train()\n",
    "    Dec.train()\n",
    "    Disc.train()\n",
    "    train(epoch, Enc, Dec, Disc, train_log)\n",
    "    Enc.eval()\n",
    "    Dec.eval()\n",
    "    Disc.eval()\n",
    "    test(Enc, Dec, Disc, valid_loader, epoch, test_log)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
